{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c698513-21b6-4081-841b-a81561a46603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "from os.path import dirname, realpath\n",
    "\n",
    "import hashlib\n",
    "import datetime\n",
    "import datetime as datetime\n",
    "sys.path.append(\"./src/\")\n",
    "#from disrisknet.utils.parsing import parse_args\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cc90ce-cf7a-4c51-b039-9382e04ac4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(dirname(dirname(realpath(os.getcwd()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bad053-b30d-4cbf-872d-9ebcba09c6b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_path = \"G:\\\\FillmoreCancerData\\\\markhe\\\\VTERisk\" \n",
    "src_path2 = \"G:\\\\FillmoreCancerData\\\\markhe\\\\VTERisk - Copy\" \n",
    "\n",
    "def md5(key):\n",
    "    return hashlib.md5(repr(key).encode()).hexdigest()\n",
    "\n",
    "testDF = pd.read_csv(os.path.join(src_path2, 'Notebooks/Find/fixed_dx.csv'))\n",
    "pat_ids = (testDF['patient_id'] ).astype(int)\n",
    "\n",
    "testDF['pids'] = pat_ids.apply(md5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61472faa-31ff-4f53-8396-6f8c025ab1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dc20797-4425-4c1c-8775-0bbb7e83e7c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logpath = os.path.join(src_path ,'logs_transformer_vte/H/11_7/', \"d93e7956f15305ad23c78d6884ca2816.results.test_preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf958ade-c7ab-443a-87b3-2810967a4c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outpath = os.path.join(src_path ,'Notebooks//PostRun_Analysis//output/Multi', \"J10DX.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e28f5e-f496-422c-ae90-6966c05583b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tdf = pd.DataFrame({'patient_id': (testDF['patient_id'] ),    \n",
    "                    'pids': (testDF['pids'] ),    \n",
    "                  'dob': (testDF['dob'] ),  \n",
    "                  'outcome_date': (testDF['outcome_date'] ), \n",
    "                  'obs_time_end': (testDF['obs_time_end'] ),  \n",
    "                  'index_date': (testDF['index_date'] ),  \n",
    "                  'diag_date': (testDF['diag_date'] ),  \n",
    "                  'outcome': (testDF['outcome'])    })\n",
    "\n",
    "with open(logpath, 'rb') as f:\n",
    "    R = pickle.load(f)\n",
    "    p = np.array(R['probs'])\n",
    "\n",
    "Df = pd.DataFrame.from_dict(R)\n",
    "Df['probs'] = Df['probs'].astype(float)\n",
    "Df['exams'] = Df['exams'].astype(int)\n",
    "M = pd.merge(tdf, Df)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbf11dd5-2946-4f5c-a9f6-88b4406ae431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "82988    False\n",
       "82989    False\n",
       "82990    False\n",
       "82991    False\n",
       "82992    False\n",
       "Name: golds, Length: 82993, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Df['golds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548a731e-1f79-47f6-b737-e0bc0bdd2ae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = np.array((Df['probs']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81135e92-b7bf-4f8c-a91b-2e8a3ef9ff44",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2147285 , 0.12524192, 0.07535204, ..., 0.14071263, 0.0988251 ,\n",
       "       0.11033526])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c16fae5d-7b05-4b9b-91fc-682c5490945c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82993"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fad1337-0b27-4a10-ae30-2e4de1156044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x0= np.zeros( shape = [len(Df),2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6bc063f-447b-4d0f-ab4b-324b8d644637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x0[:,0] = Df['probs'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b2faa97-8f68-421d-b84c-2281ed6ca7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2147285 , 0.        ],\n",
       "       [0.12524192, 0.        ],\n",
       "       [0.07535204, 0.        ],\n",
       "       ...,\n",
       "       [0.14071263, 0.        ],\n",
       "       [0.0988251 , 0.        ],\n",
       "       [0.11033526, 0.        ]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efd14798-8fc9-4f21-9ba3-be4299e55af5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot construct a dtype from an array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m m_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_numpy(), np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(Df)))\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot construct a dtype from an array"
     ]
    }
   ],
   "source": [
    "#m_pred = np.array(Df['probs'].to_numpy(), np.zeros(len(Df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db24f14d-7a18-49ca-9ce8-09a5ffd9a96e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.array(Df['golds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f034c75-b10e-49eb-9642-2a9052c5b1fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _row_max_normalization(data: np.ndarray) -> np.ndarray:\n",
    "    '''Normalise the output by subtracting\n",
    "       the per-row maximum element.\n",
    "    '''\n",
    "    row_max: np.ndarray = np.max(data,   axis = 1,  keepdims = True )\n",
    "  #  row_max: np.ndarray = data \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5c090e3-d187-45bb-abf6-0ad5406fdaf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2147285 , 0.        ],\n",
       "       [0.12524192, 0.        ],\n",
       "       [0.07535204, 0.        ],\n",
       "       ...,\n",
       "       [0.14071263, 0.        ],\n",
       "       [0.0988251 , 0.        ],\n",
       "       [0.11033526, 0.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_row_max_normalization(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e60ec81c-5c4d-4b55-a7a6-67398ab72110",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _softmax_T(predictions: np.ndarray, \n",
    "               temperature: float,\n",
    "              ) -> np.ndarray:\n",
    "    '''Softmax function scaled by the\n",
    "       inverse temperature.\n",
    "    '''\n",
    "    \n",
    "    softmax_T_output: np.ndarray = predictions\n",
    "    softmax_T_output = _row_max_normalization(softmax_T_output)  \n",
    "    softmax_T_output /= temperature  \n",
    "    softmax_T_output = softmax(softmax_T_output, \n",
    "                               axis = 1\n",
    "                              )\n",
    "    softmax_T_output = softmax_T_output.astype(dtype = predictions.dtype)\n",
    "    \n",
    "    return softmax_T_output\n",
    "\n",
    "def _exp_T(predictions: np.ndarray, \n",
    "           temperature: float\n",
    "          ) -> np.ndarray:\n",
    "    '''Scale by inverse temperature,\n",
    "       and then apply the nature\n",
    "       exponential function\n",
    "    '''\n",
    "    \n",
    "    exp_T_output: np.ndarray = predictions\n",
    "    exp_T_output = _row_max_normalization(exp_T_output)\n",
    "    exp_T_output /= temperature\n",
    "    exp_T_output = np.exp(exp_T_output)\n",
    "    \n",
    "    return exp_T_output \n",
    "\n",
    "def temperature_scaling(predictions: np.ndarray, \n",
    "                         labels: np.ndarray, \n",
    "                         initial_temperature: float\n",
    "                        ) -> float:\n",
    "    \n",
    "    def negative_log_likelihood(temperature: float):\n",
    "        '''Negative Log Likelihood Loss with respect\n",
    "           to Temperature\n",
    "        '''\n",
    "        \n",
    "        # Losses\n",
    "        losses: np.ndarray = _softmax_T(predictions, \n",
    "                                          temperature\n",
    "                                         )\n",
    "            \n",
    "        # Select the probability of the correct class\n",
    "        losses = losses[np.arange(losses.shape[0]), \n",
    "                        labels\n",
    "                       ]\n",
    "        \n",
    "        losses = np.log(losses)\n",
    "        \n",
    "        # Derivates with respect to Temperature\n",
    "        exp_T: np.ndarray = _exp_T(predictions, temperature)\n",
    "        exp_T_sum = exp_T.sum(axis = 1)\n",
    "        \n",
    "        term_1: np.ndarray = _row_max_normalization(predictions)\n",
    "        term_1 /= temperature ** 2\n",
    "        term_1 = - term_1[np.arange(term_1.shape[0]), \n",
    "                          labels\n",
    "                         ]\n",
    "        term_1 *= exp_T_sum\n",
    "                \n",
    "        term_2: np.ndarray = _row_max_normalization(predictions)\n",
    "        term_2 /= temperature ** 2\n",
    "        term_2 = _row_max_normalization(term_2)\n",
    "        term_2 *= exp_T\n",
    "        term_2 = term_2.sum(axis = 1)\n",
    "        \n",
    "        dL_dts: np.ndarray = (term_1 + term_2) / exp_T_sum\n",
    "            \n",
    "        # print(f\"{-losses.sum() = },  {-dL_dts.sum() = }\")\n",
    "            \n",
    "        return -losses.sum(),  -dL_dts.sum()\n",
    "    \n",
    "    temperature_minimizer: minimize = minimize(negative_log_likelihood, \n",
    "                                               initial_temperature, \n",
    "                                               method = \"L-BFGS-B\",\n",
    "                                               jac = True,\n",
    "                                               options = {\"gtol\": 1e-6,\n",
    "                                                           \"ftol\": 64 * np.finfo(float).eps,\n",
    "                                                         }\n",
    "                                              )\n",
    "        \n",
    "    return temperature_minimizer.x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "16572f10-6f8d-4742-8d61-1436ac3b75dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "010698fb-de07-4706-bee4-0ca47272498d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6b2c2109-59d0-4850-9067-eddd3bed3751",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82993,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1212d475-fd98-4131-93e0-086d0c6104e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82993, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4ed6c97-1cc4-4230-bc9e-f1f32071dbf2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array(y,dtype = int)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fa9bd203-dcd9-4b0f-9e67-5c4703561fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1533"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b0570c5-b547-4f7b-a72a-4a72ca78c15e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2147285 , 0.        ],\n",
       "       [0.12524192, 0.        ],\n",
       "       [0.07535204, 0.        ],\n",
       "       ...,\n",
       "       [0.14071263, 0.        ],\n",
       "       [0.0988251 , 0.        ],\n",
       "       [0.11033526, 0.        ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e133fc3c-f791-4603-9a5b-84d4056b1672",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82993, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7a1f67a4-a7e5-479a-83f4-a95bf53792cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2147285 , 0.12524192, 0.07535204, ..., 0.14071263, 0.0988251 ,\n",
       "        0.11033526],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "803a2bf8-031b-469c-af59-a4a4f5b75483",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cal2 = temperature_scaling((x0), z, .1)  \n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e897fa7b-0930-4305-856c-cfdec8bdd6b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9eca3476-ec16-4003-b58f-bc830b08c26c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "SVC_classifier = SVC(probability=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7a7f79ad-3321-431c-9a5f-c7c145fd5c97",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_3996\\3620560755.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  losses = np.log(losses)\n",
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_3996\\3620560755.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  exp_T_output = np.exp(exp_T_output)\n",
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_3996\\3620560755.py:74: RuntimeWarning: invalid value encountered in add\n",
      "  dL_dts: np.ndarray = (term_1 + term_2) / exp_T_sum\n",
      "D:\\Programs\\Anaconda3\\Lib\\site-packages\\scipy\\special\\_logsumexp.py:224: RuntimeWarning: invalid value encountered in subtract\n",
      "  exp_x_shifted = np.exp(x - x_max)\n"
     ]
    }
   ],
   "source": [
    "SVC_classifier.fit(X_train, y_train)\n",
    "svc_predictions = SVC_classifier.predict_proba(X_train)\n",
    "Logistic_Regression = LogisticRegression()\n",
    "Logistic_Regression.fit(X_train, y_train)\n",
    "logistic_predictions = Logistic_Regression.predict_proba(X_train)\n",
    "temp = temperature_scaling(svc_predictions, y_train, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e92fbf4a-b41e-4331-a441-5cb985fed4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_3996\\3620560755.py:29: RuntimeWarning: overflow encountered in exp\n",
      "  exp_T_output = np.exp(exp_T_output)\n",
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_3996\\3620560755.py:74: RuntimeWarning: invalid value encountered in add\n",
      "  dL_dts: np.ndarray = (term_1 + term_2) / exp_T_sum\n",
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_3996\\3620560755.py:53: RuntimeWarning: divide by zero encountered in log\n",
      "  losses = np.log(losses)\n"
     ]
    }
   ],
   "source": [
    "temp2 = temperature_scaling(logistic_predictions, y_train, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "deabeec3-c66f-4160-a6c4-95f38dde0612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.118859322679242"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fd086764-5b80-4d6b-bc89-4b9ac1b59a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1200943073833476"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "418fea47-01bd-4949-90e4-a291e6965039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 2, 0, 0, 1, 1, 2, 1, 2, 0, 2, 0, 2, 0, 1, 1, 1, 2, 0,\n",
       "       0, 1, 1, 1, 2, 2, 2, 1, 0, 1, 0, 2, 2, 2, 0, 1, 1, 1, 0, 1, 2, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 2, 1, 1, 2, 0, 2, 1, 2, 0, 1, 2, 1, 2, 0, 0,\n",
       "       1, 2, 0, 1, 0, 2, 0, 1, 0, 2, 1, 2, 2, 1, 2, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 2, 2, 0, 0, 0, 2, 0, 2, 2, 1, 0, 2, 1, 0, 2, 1, 2, 1, 2,\n",
       "       2, 0])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "be2d698a-b0a0-4b54-a984-b0e1c92f7016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ff2c4d2-b2d4-4a8e-80d0-3d008a2758f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(svc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad669a26-25f3-4a0e-ab12-9ee09eb41c54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svc_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d0de6c-69ca-401a-95e9-ad854d3fe6b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logistic_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "15467d69-2fd2-4b3a-9283-9c31cda49b57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "90cb4247-9a21-47ad-9435-9e5c08406bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan],\n",
       "       [nan, nan, nan]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " logistic_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b370a-b6b9-4805-8863-7856af2bf68c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #M.to_csv(outpath) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532d82a-e614-4d38-ad99-de7cfb9aefc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b7abc-d04e-48c4-83da-868707c11911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e6efdc5-58d9-4549-bbad-c078f75c897b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_84892\\383890625.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  m['d']= pd.to_datetime(m['outcome_date']) - pd.to_datetime(m['model_date'])\n",
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_84892\\383890625.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  m['d']= pd.to_datetime(m['outcome_date']) - pd.to_datetime(m['model_date'])\n",
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_84892\\383890625.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  m_VE0[\"outcome\"] = m_VE0[\"outcome\"].replace(True, False)\n"
     ]
    }
   ],
   "source": [
    "M = pd.merge(g6, testDF)\n",
    "m = M[[\"patient_id\",\"dx_date\", \"index_date\", \"model_date\",  \"outcome\",\"outcome_date\",\"p6\" ]]\n",
    "m['d']= pd.to_datetime(m['outcome_date']) - pd.to_datetime(m['model_date'])\n",
    "\n",
    "#### THE PURPOSE OF THIS STEP IS TO ACTUALLY REPLACE THE 1's after 2 years with 0's! NEED it, in dxdate this is NOT updated\n",
    "m_VE = m[ m['outcome'] ]\n",
    "m_VE1 = m_VE [   (pd.to_datetime( m_VE[\"outcome_date\"] ) -pd.to_datetime( m_VE[\"index_date\"] )) < datetime.timedelta(730)]\n",
    "m_VE0 = m_VE [   (pd.to_datetime( m_VE[\"outcome_date\"] ) -pd.to_datetime( m_VE[\"index_date\"] )) >= datetime.timedelta(730)]\n",
    "m_VE0[\"outcome\"] = m_VE0[\"outcome\"].replace(True, False)  \n",
    "m0= m[ ~ m['outcome'] ]\n",
    "\n",
    "m1 = pd.concat([m_VE1, m_VE0, m0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ed76f5c-ab80-4ed9-90d1-d80ede20287a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5600783435183764"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(m1['outcome'],  m1['p6'], average = 'samples')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d65ee1e0-3c7e-4767-a358-7cb1270fd1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72681,     5],\n",
       "       [ 4301,     0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( confusion_matrix (m1['outcome'],  m1['p6']>.5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "981bbaf3-1a93-4618-ae9f-ffd7bc3793d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many people had event within 6 months of index date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71bb4d3a-4549-4dfe-8de3-36719dbcf4ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1.to_csv('output/XCoh_Sen.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28235e3d-d8e2-424b-b064-e0b9d45c7881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m1.to_csv('output/XCoh_Sen.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "112b112b-b97d-4328-9fb2-a9aa34b70486",
   "metadata": {},
   "outputs": [],
   "source": [
    "#m1.to_excel('output/dxMD_Sensitivity90.xlsx') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecc15a95-38ea-4f44-a4be-1692fb6bebac",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'len180'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'len180'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m statistics\u001b[38;5;241m.\u001b[39mquantiles( M[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlen180\u001b[39m\u001b[38;5;124m'\u001b[39m],n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mD:\\Programs\\Anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'len180'"
     ]
    }
   ],
   "source": [
    "statistics.quantiles( M['len180'],n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df19f012-3361-4e45-bd01-22dd2fc015cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2.2715e+04, 1.8050e+03, 1.3000e+02, 2.5000e+01, 1.2000e+01,\n",
       "        1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 2.0000e+00]),\n",
       " array([1.00000e+00, 2.37810e+03, 4.75520e+03, 7.13230e+03, 9.50940e+03,\n",
       "        1.18865e+04, 1.42636e+04, 1.66407e+04, 1.90178e+04, 2.13949e+04,\n",
       "        2.37720e+04]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.hist(M['len180'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1d9a19-4dbb-4201-bcb9-8ecaaea3619a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2943eb76-d00c-40a6-b788-9be6f1250aae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_73432\\1057840980.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  m['d']= pd.to_datetime(m['outcome_date']) - pd.to_datetime(m['model_date'])\n",
      "C:\\Users\\VHANYNHeT\\AppData\\Local\\Temp\\2\\ipykernel_73432\\1057840980.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  m_VE0[\"outcome\"] = m_VE0[\"outcome\"].replace(True, False)\n"
     ]
    }
   ],
   "source": [
    "m['d']= pd.to_datetime(m['outcome_date']) - pd.to_datetime(m['model_date'])\n",
    "m_VE = m[ m['outcome'] ]\n",
    "m_VE1 = m_VE [   (pd.to_datetime( m_VE[\"outcome_date\"] ) -pd.to_datetime( m_VE[\"index_date\"] )) < datetime.timedelta(730)]\n",
    "m_VE0 = m_VE [   (pd.to_datetime( m_VE[\"outcome_date\"] ) -pd.to_datetime( m_VE[\"index_date\"] )) >= datetime.timedelta(730)]\n",
    "m_VE0[\"outcome\"] = m_VE0[\"outcome\"].replace(True, False)  \n",
    "m0= m[ ~ m['outcome'] ]\n",
    "\n",
    "m1 = pd.concat([m_VE1, m_VE0, m0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
